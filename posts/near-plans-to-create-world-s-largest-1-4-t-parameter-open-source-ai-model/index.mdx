---
title: "The Best Cheap Phones for Almost Every Budget"
subtitle: "The 1.4 trillion parameter model would be 3.5 times bigger than Meta’s current open-source Llama model."
date: "2024-11-10"
slug: "near-plans-to-create-world-s-largest-1-4-t-parameter-open-source-ai-model"
hero_image: "./near-plans-to-create-world-s-largest-1-4-t-parameter-open-source-ai-model.jpg"
hero_image_alt: "Near plans to build world’s largest 1.4T parameter open-source AI model"
hero_image_credit_link: "https://cointelegraph.com/news/near-plans-to-create-world-s-largest-1-4-t-parameter-open-source-ai-model?utm_source=tldrai"
---

Near Protocol has unveiled an ambitious plan to build the world’s largest open-source artificial intelligence model on the opening day of its Redacted conference in Bangkok, Thailand. The 1.4 trillion parameter model would be 3.5 times bigger than Meta’s current open-source Llama model.

It will be created through competitive crowdsourced research and development from thousands of contributors on the new Near AI Research hub, with participants able to join the training of a small 500 million parameter model from today, Nov. 10.

Near Protocol’s ambitious AI model
The project will grow in size and sophistication across seven models, with only the best contributors making the leap to working on progressively more complex and larger models. The models will be monetized and privacy will be preserved via the use of encrypted Trusted Execution Environments to reward contributors and encourage constant updating as the technology progresses.

Related: Near patches critical bug that could crash every node on the network

The expensive training and compute will be funded with token sales, Near Protocol co-founder Illia Polosukhin told Cointelegraph at the Redacted conference in Bangkok.